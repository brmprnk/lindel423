{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "motivated-committee",
   "metadata": {},
   "source": [
    "## Import and Cleanup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "romantic-sending",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from sklearn.cross_decomposition import CCA\n",
    "import matplotlib.pyplot as plt\n",
    "from mca import MCA\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd9e3705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded\n"
     ]
    }
   ],
   "source": [
    "## If data already preprocessed, load it in, else do preprocessing\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv('./data/Lindel_alldata.csv', index_col=0)\n",
    "    print(\"Data successfully loaded\")\n",
    "except Exception:\n",
    "    label, rev_index, features = pkl.load(open('./data/feature_index_all.pkl','rb'))\n",
    "    Lindel_training = pd.read_csv(\"./data/Lindel_training_65bp.csv\", sep=',', index_col=0)\n",
    "    Lindel_test = pd.read_csv(\"./data/Lindel_test_65bp.csv\", sep=',', index_col=0)\n",
    "\n",
    "    print(\"Number of labels : \", len(label.keys()))\n",
    "    print(\"Number of rev_index : \", len(rev_index.keys()))\n",
    "    print(\"Number of features : \", len(features.keys()))\n",
    "\n",
    "    # column descriptions\n",
    "    # Lindel_training.iloc[0] # guide sequences\n",
    "    # Lindel_training.iloc[1:3034] # 3033 binary features [2649 MH binary features + 384 one hot encoded features]\n",
    "    # Lindel_training.iloc[3034:] # 557 observed outcome frequencies\n",
    "\n",
    "    # # Merge training and test set for dimensionality reduction\n",
    "    all_data = pd.concat([Lindel_training, Lindel_test])\n",
    "    # data_features = all_data.iloc[:, 1:3034]\n",
    "\n",
    "    # # Clean up data\n",
    "    features = dict(sorted(features.items(), key=lambda item: item[1]))\n",
    "    feature_labels = list(features.keys())\n",
    "\n",
    "    labels = dict(sorted(label.items(), key=lambda item: item[1]))\n",
    "    class_labels = list(labels.keys())\n",
    "\n",
    "    one_hot_labels = []\n",
    "    for i in range(80):\n",
    "        one_hot_labels.append(\"nt {}\".format(str(int(i / 4) + 1)))\n",
    "\n",
    "    for i in range(304):\n",
    "        one_hot_labels.append(\"2nt {}\".format(str(int(i / 16) + 1)))\n",
    "\n",
    "    one_hot_labels = np.array(one_hot_labels)\n",
    "\n",
    "    column_labels = np.concatenate((np.array(['Guide Sequence', '65bp']), feature_labels, one_hot_labels, class_labels))\n",
    "\n",
    "    # Rename columns of test and training set\n",
    "    Lindel_training = Lindel_training.set_axis(column_labels, axis=1, inplace=False)\n",
    "    Lindel_test = Lindel_test.set_axis(column_labels, axis=1, inplace=False)\n",
    "\n",
    "    data = pd.concat([Lindel_training, Lindel_test], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8500787a",
   "metadata": {},
   "source": [
    "## Run LINDEL Model, all configurations that do not require dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c97c1bd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4788, 3590) <class 'numpy.ndarray'>\n",
      "X Shape  (4788, 3033)  | y shape  (4788, 557)\n",
      "Now removing samples with only insertion events\n",
      "X_deletion Shape  (4657, 3033)  | y_deletion shape  (4657, 536)\n",
      "The first index of the first split is  466\n",
      "Number of train/val splits:  10\n"
     ]
    }
   ],
   "source": [
    "# Do data preprocessing\n",
    "\n",
    "import pickle as pkl\n",
    "import os,sys,csv,re\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.regularizers import l2, l1\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.callbacks import *\n",
    "\n",
    "# Make the data preprocessing a deterministic process\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define useful functions\n",
    "def mse(x, y):\n",
    "    return ((x-y)**2).mean()\n",
    "\n",
    "def corr(x, y):\n",
    "    return np.corrcoef(x, y)[0, 1] ** 2\n",
    "\n",
    "def onehotencoder(seq):\n",
    "    nt= ['A','T','C','G']\n",
    "    head = []\n",
    "    l = len(seq)\n",
    "    for k in range(l):\n",
    "        for i in range(4):\n",
    "            head.append(nt[i]+str(k))\n",
    "\n",
    "    for k in range(l-1):\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                head.append(nt[i]+nt[j]+str(k))\n",
    "    head_idx = {}\n",
    "    for idx,key in enumerate(head):\n",
    "        head_idx[key] = idx\n",
    "    encode = np.zeros(len(head_idx))\n",
    "    for j in range(l):\n",
    "        encode[head_idx[seq[j]+str(j)]] =1.\n",
    "    for k in range(l-1):\n",
    "        encode[head_idx[seq[k:k+2]+str(k)]] =1.\n",
    "    return encode\n",
    "\n",
    "def kfoldsplits(X):\n",
    "    \"\"\"Split annotations\"\"\"\n",
    "    kf = KFold(n_splits=10, shuffle=False)\n",
    "    splits = []\n",
    "    for trainIdx, validIdx in kf.split(X):\n",
    "        splits.append((trainIdx, validIdx))\n",
    "        \n",
    "    print(\"The first index of the first split is \", splits[0][0][0])\n",
    "\n",
    "    return splits\n",
    "\n",
    "# Preprocess data\n",
    "model_data = data.values[:,2:].astype(np.float32)\n",
    "print(model_data.shape, type(model_data))\n",
    "\n",
    "# Sum up deletions and insertions to\n",
    "X = model_data[:, :(2649 + 384)]\n",
    "y = model_data[:, (2649 + 384):]\n",
    "\n",
    "print(\"X Shape \", X.shape, \" | y shape \", y.shape)\n",
    "\n",
    "# Randomly shuffle data\n",
    "idx = np.arange(len(y))\n",
    "np.random.shuffle(idx)\n",
    "X, y = X[idx], y[idx]\n",
    "\n",
    "print(\"Now removing samples with only insertion events\")\n",
    "X_deletion, y_deletion = [], []\n",
    "\n",
    "# Remove samples that only have insertion events:\n",
    "for i in range(model_data.shape[0]):\n",
    "    if 1> sum(y[i,:536])> 0 :\n",
    "        y_deletion.append(y[i,:536]/sum(y[i,:536]))\n",
    "        X_deletion.append(X[i])\n",
    "        \n",
    "X_deletion, y_deletion = np.array(X_deletion), np.array(y_deletion)\n",
    "\n",
    "print(\"X_deletion Shape \", X_deletion.shape, \" | y_deletion shape \", y_deletion.shape)\n",
    "\n",
    "\n",
    "\n",
    "splits = kfoldsplits(X_deletion)\n",
    "print(\"Number of train/val splits: \", len(splits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7434386e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save dir is  ./results/20-03-2022 14:29:50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-61-b8f7717c070c>:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm(range(len(splits))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda9e70de69140a6a0467ce7d9288a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model  1 of 10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [61]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m536\u001b[39m,  activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(X_deletion\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],), kernel_regularizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m     38\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 39\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m              \u001b[49m\u001b[43mtensorboard_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m              \u001b[49m\u001b[43mmodel_checkpoint_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m              \u001b[49m\u001b[43mcsv_logger\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_valid)\n\u001b[1;32m     46\u001b[0m baseline_errors\u001b[38;5;241m.\u001b[39mappend(mse(y_hat, y_valid))\n",
      "File \u001b[0;32m~/miniconda3/envs/bio/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:66\u001b[0m, in \u001b[0;36menable_multi_worker.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_method_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     65\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_multi_worker_mode():  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m   \u001b[38;5;66;03m# Running inside `run_distribute_coordinator` already.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dc_context\u001b[38;5;241m.\u001b[39mget_current_worker_context():\n",
      "File \u001b[0;32m~/miniconda3/envs/bio/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:848\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m traceme\u001b[38;5;241m.\u001b[39mTraceMe(\n\u001b[1;32m    842\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraceContext\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    843\u001b[0m     graph_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    844\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m    845\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m    846\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size):\n\u001b[1;32m    847\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 848\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    849\u001b[0m   \u001b[38;5;66;03m# Catch OutOfRangeError for Datasets of unknown size.\u001b[39;00m\n\u001b[1;32m    850\u001b[0m   \u001b[38;5;66;03m# This blocks until the batch has finished executing.\u001b[39;00m\n\u001b[1;32m    851\u001b[0m   \u001b[38;5;66;03m# TODO(b/150292341): Allow multiple async steps here.\u001b[39;00m\n\u001b[1;32m    852\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39minferred_steps:\n",
      "File \u001b[0;32m~/miniconda3/envs/bio/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:580\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m     xla_context\u001b[38;5;241m.\u001b[39mExit()\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 580\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_count \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tracing_count():\n\u001b[1;32m    583\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_counter\u001b[38;5;241m.\u001b[39mcalled_without_tracing()\n",
      "File \u001b[0;32m~/miniconda3/envs/bio/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:611\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    609\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    610\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    613\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    614\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    615\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/bio/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2420\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2419\u001b[0m   graph_function, args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filtered_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bio/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1661\u001b[0m, in \u001b[0;36mConcreteFunction._filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1647\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_filtered_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args, kwargs):\n\u001b[1;32m   1648\u001b[0m   \u001b[38;5;124;03m\"\"\"Executes the function, filtering arguments from the Python function.\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m \n\u001b[1;32m   1650\u001b[0m \u001b[38;5;124;03m  Objects aside from Tensors, CompositeTensors, and Variables are ignored.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1659\u001b[0m \u001b[38;5;124;03m    `args` and `kwargs`.\u001b[39;00m\n\u001b[1;32m   1660\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1661\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m      \u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m       \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mresource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBaseResourceVariable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bio/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1740\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1741\u001b[0m     pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_TapeSetPossibleGradientTypes(args))\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m _POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/bio/lib/python3.8/site-packages/tensorflow/python/eager/function.py:593\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    592\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 593\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    600\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    601\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    602\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    605\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    606\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/bio/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Make results dir\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "save_dir = os.path.join('./results', dt_string)\n",
    "os.makedirs(save_dir)\n",
    "\n",
    "print(\"Save dir is \", save_dir)\n",
    "\n",
    "# Train model: No regularization, no early stopping\n",
    "baseline_errors = []\n",
    "for i in tqdm(range(len(splits))):\n",
    "    print(\"Training model \", (i+1), \"of 10\")\n",
    "\n",
    "    train_split, val_split = splits[i]\n",
    "    \n",
    "    x_train = X_deletion[train_split]\n",
    "    x_valid = X_deletion[val_split]\n",
    "    \n",
    "    y_train = y_deletion[train_split]\n",
    "    y_valid = y_deletion[val_split]\n",
    "    \n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"{}/logs\".format(save_dir))\n",
    "    \n",
    "    checkpoint_name = save_dir + '/baseline_cp{}'.format(i)\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath= checkpoint_name + '-{epoch:02d}.h5',\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode=\"min\")\n",
    "    \n",
    "    csv_logger = CSVLogger('{}/training{}.log'.format(save_dir, i), separator=',', append=False)\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(536,  activation='softmax', input_shape=(X_deletion.shape[1],), kernel_regularizer=None))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['mse'])\n",
    "    history = model.fit(x_train, y_train, epochs=100, validation_data=(x_valid, y_valid),\n",
    "              callbacks=[\n",
    "                  tensorboard_callback,\n",
    "                  model_checkpoint_callback,\n",
    "                  csv_logger], verbose=0)\n",
    "    \n",
    "    y_hat = model.predict(x_valid)\n",
    "    baseline_errors.append(mse(y_hat, y_valid))\n",
    "    \n",
    "# Train model: No regularization, no early stopping\n",
    "baseline_errors = []\n",
    "for i in tqdm(range(len(splits))):\n",
    "    print(\"Training model \", (i+1), \"of 10\")\n",
    "\n",
    "    train_split, val_split = splits[i]\n",
    "    \n",
    "    x_train = X_deletion[train_split]\n",
    "    x_valid = X_deletion[val_split]\n",
    "    \n",
    "    y_train = y_deletion[train_split]\n",
    "    y_valid = y_deletion[val_split]\n",
    "    \n",
    "    \n",
    "    # Train models TODO: Wait until Q2 is answered\n",
    "    lambdas = 10 ** np.arange(-10, -1, 0.1)\n",
    "    \n",
    "    errors_l1, errors_l2 = [], []\n",
    "    for l in tqdm(lambdas):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(536,  activation='softmax', input_shape=(size_input,), kernel_regularizer=l2(l)))\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['mse'])\n",
    "        model.fit(x_train, y_train, epochs=100, validation_data=(x_valid, y_valid), verbose=0)\n",
    "        y_hat = model.predict(x_valid)\n",
    "        errors_l2.append(mse(y_hat, y_valid))\n",
    "\n",
    "    for l in tqdm(lambdas):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(536,  activation='softmax', input_shape=(size_input,), kernel_regularizer=l1(l)))\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['mse'])\n",
    "        model.fit(x_train, y_train, epochs=100, validation_data=(x_valid, y_valid), verbose=0)\n",
    "        y_hat = model.predict(x_valid)\n",
    "        errors_l1.append(mse(y_hat, y_valid))\n",
    "    \n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"{}/logs\".format(save_dir))\n",
    "    \n",
    "    checkpoint_name = save_dir + '/baseline_cp{}'.format(i)\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath= checkpoint_name + '-{epoch:02d}.h5',\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode=\"min\")\n",
    "    \n",
    "    csv_logger = CSVLogger('{}/training{}.log'.format(save_dir, i), separator=',', append=False)\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(536,  activation='softmax', input_shape=(X_deletion.shape[1],), kernel_regularizer=None))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['mse'])\n",
    "    history = model.fit(x_train, y_train, epochs=100, validation_data=(x_valid, y_valid),\n",
    "              callbacks=[\n",
    "                  tensorboard_callback,\n",
    "                  model_checkpoint_callback,\n",
    "                  csv_logger], verbose=0)\n",
    "    \n",
    "    y_hat = model.predict(x_valid)\n",
    "    baseline_errors.append(mse(y_hat, y_valid))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da7a263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b34dc2307e58e1a1d1e57cf7ef01b077b034c069b8a201720687e01a8602b64b"
  },
  "kernelspec": {
   "display_name": "bio",
   "language": "python",
   "name": "bio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
