{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "motivated-committee",
   "metadata": {},
   "source": [
    "## Import and Cleanup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "romantic-sending",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from sklearn.cross_decomposition import CCA\n",
    "import matplotlib.pyplot as plt\n",
    "from mca import MCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd9e3705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded\n"
     ]
    }
   ],
   "source": [
    "## If data already preprocessed, load it in, else do preprocessing\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv('./data/finaltv.csv', index_col=0)\n",
    "    test = pd.read_csv('./data/finaltest.csv', index_col=0)\n",
    "    print(\"Data successfully loaded\")\n",
    "except Exception:\n",
    "    label, rev_index, features = pkl.load(open('./data/feature_index_all.pkl','rb'))\n",
    "    Lindel_training = pd.read_csv(\"./data/Lindel_training_65bp.csv\", sep=',', index_col=0)\n",
    "    Lindel_test = pd.read_csv(\"./data/Lindel_test_65bp.csv\", sep=',', index_col=0)\n",
    "\n",
    "    print(\"Number of labels : \", len(label.keys()))\n",
    "    print(\"Number of rev_index : \", len(rev_index.keys()))\n",
    "    print(\"Number of features : \", len(features.keys()))\n",
    "\n",
    "    # column descriptions\n",
    "    # Lindel_training.iloc[0] # guide sequences\n",
    "    # Lindel_training.iloc[1:3034] # 3033 binary features [2649 MH binary features + 384 one hot encoded features]\n",
    "    # Lindel_training.iloc[3034:] # 557 observed outcome frequencies\n",
    "\n",
    "    # # Merge training and test set for dimensionality reduction\n",
    "    all_data = pd.concat([Lindel_training, Lindel_test])\n",
    "    # data_features = all_data.iloc[:, 1:3034]\n",
    "\n",
    "    # # Clean up data\n",
    "    features = dict(sorted(features.items(), key=lambda item: item[1]))\n",
    "    feature_labels = list(features.keys())\n",
    "\n",
    "    labels = dict(sorted(label.items(), key=lambda item: item[1]))\n",
    "    class_labels = list(labels.keys())\n",
    "\n",
    "    one_hot_labels = []\n",
    "    for i in range(80):\n",
    "        one_hot_labels.append(\"nt {}\".format(str(int(i / 4) + 1)))\n",
    "\n",
    "    for i in range(304):\n",
    "        one_hot_labels.append(\"2nt {}\".format(str(int(i / 16) + 1)))\n",
    "\n",
    "    one_hot_labels = np.array(one_hot_labels)\n",
    "\n",
    "    column_labels = np.concatenate((np.array(['Guide Sequence', '65bp']), feature_labels, one_hot_labels, class_labels))\n",
    "\n",
    "    # Rename columns of test and training set\n",
    "    Lindel_training = Lindel_training.set_axis(column_labels, axis=1, inplace=False)\n",
    "    Lindel_test = Lindel_test.set_axis(column_labels, axis=1, inplace=False)\n",
    "\n",
    "    Lindel_training.to_csv('./data/finaltv.csv')\n",
    "    Lindel_test.to_csv('./data/finaltest.csv')\n",
    "\n",
    "    data = pd.concat([Lindel_training, Lindel_test], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee53ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6191f7d1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# RUN DIMENSIONALITY REDUCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "414a2bd9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4349, 3590) <class 'numpy.ndarray'>\n",
      "X Shape  (4349, 3033)  | y shape  (4349, 557)\n",
      "Now removing samples with only insertion events\n",
      "X_test_deletion Shape  (427, 3033)  | y_test_deletion shape  (427, 536)\n",
      "The first index of the first split is  423\n",
      "Number of train/val splits:  10\n"
     ]
    }
   ],
   "source": [
    "# Do data preprocessing\n",
    "\n",
    "import pickle as pkl\n",
    "import os,sys,csv,re\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.regularizers import l2, l1\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.callbacks import *\n",
    "\n",
    "# Make the data preprocessing a deterministic process\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define useful functions\n",
    "def mse(x, y):\n",
    "    return ((x-y)**2).mean()\n",
    "\n",
    "def corr(x, y):\n",
    "    return np.corrcoef(x, y)[0, 1] ** 2\n",
    "\n",
    "def onehotencoder(seq):\n",
    "    nt= ['A','T','C','G']\n",
    "    head = []\n",
    "    l = len(seq)\n",
    "    for k in range(l):\n",
    "        for i in range(4):\n",
    "            head.append(nt[i]+str(k))\n",
    "\n",
    "    for k in range(l-1):\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                head.append(nt[i]+nt[j]+str(k))\n",
    "    head_idx = {}\n",
    "    for idx,key in enumerate(head):\n",
    "        head_idx[key] = idx\n",
    "    encode = np.zeros(len(head_idx))\n",
    "    for j in range(l):\n",
    "        encode[head_idx[seq[j]+str(j)]] =1.\n",
    "    for k in range(l-1):\n",
    "        encode[head_idx[seq[k:k+2]+str(k)]] =1.\n",
    "    return encode\n",
    "\n",
    "def kfoldsplits(X):\n",
    "    \"\"\"Split annotations\"\"\"\n",
    "    kf = KFold(n_splits=10, shuffle=False)\n",
    "    splits = []\n",
    "    for trainIdx, validIdx in kf.split(X):\n",
    "        splits.append((trainIdx, validIdx))\n",
    "        \n",
    "    print(\"The first index of the first split is \", splits[0][0][0])\n",
    "\n",
    "    return splits\n",
    "\n",
    "# Preprocess data\n",
    "model_data = data.values[:,2:].astype(np.float32)\n",
    "test_data = test.values[:, 2:].astype(np.float32)\n",
    "print(model_data.shape, type(model_data))\n",
    "\n",
    "# Sum up deletions and insertions to\n",
    "X = model_data[:, :(2649 + 384)]\n",
    "y = model_data[:, (2649 + 384):]\n",
    "\n",
    "X_test = test_data[:, :(2649 + 384)]\n",
    "y_test = test_data[:, (2649 + 384):]\n",
    "\n",
    "print(\"X Shape \", X.shape, \" | y shape \", y.shape)\n",
    "\n",
    "# Randomly shuffle data\n",
    "idx = np.arange(len(y))\n",
    "np.random.shuffle(idx)\n",
    "X, y = X[idx], y[idx]\n",
    "test_idx = np.arange(len(y_test))\n",
    "np.random.shuffle(test_idx)\n",
    "X_test, y_test = X_test[test_idx], y_test[test_idx]\n",
    "\n",
    "print(\"Now removing samples with only insertion events\")\n",
    "X_deletion, y_deletion = [], []\n",
    "X_test_deletion, y_test_deletion = [], []\n",
    "\n",
    "# Remove samples that only have insertion events:\n",
    "for i in range(model_data.shape[0]):\n",
    "    if 1> sum(y[i,:536])> 0 :\n",
    "        y_deletion.append(y[i,:536]/sum(y[i,:536]))\n",
    "        X_deletion.append(X[i])\n",
    "        \n",
    "X_deletion, y_deletion = np.array(X_deletion), np.array(y_deletion)\n",
    "\n",
    "for i in range(test_data.shape[0]):\n",
    "    if 1> sum(y_test[i,:536])> 0 :\n",
    "        y_test_deletion.append(y_test[i,:536]/sum(y_test[i,:536]))\n",
    "        X_test_deletion.append(X_test[i])\n",
    "        \n",
    "X_test_deletion, y_test_deletion = np.array(X_test_deletion), np.array(y_test_deletion)\n",
    "\n",
    "print(\"X_test_deletion Shape \", X_test_deletion.shape, \" | y_test_deletion shape \", y_test_deletion.shape)\n",
    "\n",
    "\n",
    "\n",
    "splits = kfoldsplits(X_deletion)\n",
    "print(\"Number of train/val splits: \", len(splits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489d235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns[2:(2649 + 384 + 2)].values.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441d7099",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1 : PCA\n",
    "\n",
    "for i in range(1):\n",
    "\n",
    "    # Instantiate PCA\n",
    "    n_components = 910\n",
    "    pca = PCA()\n",
    "\n",
    "    # Determine transformed features\n",
    "    X_train_pca = pca.fit_transform(X_deletion)\n",
    "\n",
    "    # Determine explained variance using explained_variance_ration_ attribute\n",
    "    exp_var_pca = pca.explained_variance_ratio_\n",
    "\n",
    "    # Cumulative sum of eigenvalues; This will be used to create step plot\n",
    "    # for visualizing the variance explained by each principal component.\n",
    "    cum_sum_eigenvalues = np.cumsum(exp_var_pca)\n",
    "    print(\"Nr of components : \", n_components)\n",
    "    print(\"Total Percentage of variance explained = \", cum_sum_eigenvalues[-1] * 100)\n",
    "    #\n",
    "    # Create the visualization plot\n",
    "    #b\n",
    "    plt.bar(range(0,len(exp_var_pca)), exp_var_pca, alpha=0.5, align='center', label='Individual explained variance')\n",
    "    plt.step(range(0,len(cum_sum_eigenvalues)), cum_sum_eigenvalues, where='mid',label='Cumulative explained variance')\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Principal component index')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b423eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(pd.DataFrame(cum_sum_eigenvalues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ca933b8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pca_components = [140, 180, 237, 355, 697, 1491]\n",
    "variances = [80, 85, 90, 95, 99, 100]\n",
    "# % of variance explained: components, 80, 85, 90, 95, 99, 100(up to 6 decimals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3410ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, components in enumerate(pca_components):\n",
    "    \n",
    "    # Instantiate PCA\n",
    "    pca = PCA(n_components=components)\n",
    "\n",
    "    # Determine transformed features\n",
    "    X_pca = pca.fit_transform(X_deletion)\n",
    "    X_test_pca = pca.transform(X_test_deletion)\n",
    "    \n",
    "    np.save(\"./pca/tv_{}_var{}\".format(components, variances[i]), X_pca)\n",
    "    np.save(\"./pca/test_{}_var{}\".format(components, variances[i]), X_test_pca)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87cf50b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save dir is  ./results/28-03-2022 11:46:30\n",
      "VAE 140 80\n",
      "(3807, 140) (423, 140)\n",
      "(3807, 536) (423, 536)\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6.2220 - mse: 3.7992e-04 - val_loss: 6.1592 - val_mse: 3.7796e-04\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 6.1014 - mse: 3.7897e-04 - val_loss: 6.0427 - val_mse: 3.7699e-04\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.9887 - mse: 3.7799e-04 - val_loss: 5.9342 - val_mse: 3.7599e-04\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.8836 - mse: 3.7696e-04 - val_loss: 5.8332 - val_mse: 3.7495e-04\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.7862 - mse: 3.7591e-04 - val_loss: 5.7397 - val_mse: 3.7388e-04\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.6960 - mse: 3.7483e-04 - val_loss: 5.6536 - val_mse: 3.7280e-04\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 988us/step - loss: 5.6130 - mse: 3.7373e-04 - val_loss: 5.5746 - val_mse: 3.7170e-04\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 5.5367 - mse: 3.7262e-04 - val_loss: 5.5019 - val_mse: 3.7059e-04\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.4668 - mse: 3.7151e-04 - val_loss: 5.4358 - val_mse: 3.6949e-04\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.4030 - mse: 3.7040e-04 - val_loss: 5.3755 - val_mse: 3.6840e-04\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.3450 - mse: 3.6931e-04 - val_loss: 5.3207 - val_mse: 3.6731e-04\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.2923 - mse: 3.6823e-04 - val_loss: 5.2713 - val_mse: 3.6626e-04\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.2447 - mse: 3.6718e-04 - val_loss: 5.2264 - val_mse: 3.6522e-04\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.2017 - mse: 3.6616e-04 - val_loss: 5.1864 - val_mse: 3.6422e-04\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.1630 - mse: 3.6518e-04 - val_loss: 5.1503 - val_mse: 3.6326e-04\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.1283 - mse: 3.6424e-04 - val_loss: 5.1182 - val_mse: 3.6234e-04\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.0974 - mse: 3.6335e-04 - val_loss: 5.0893 - val_mse: 3.6146e-04\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.0697 - mse: 3.6251e-04 - val_loss: 5.0638 - val_mse: 3.6063e-04\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.0451 - mse: 3.6172e-04 - val_loss: 5.0412 - val_mse: 3.5987e-04\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.0233 - mse: 3.6099e-04 - val_loss: 5.0211 - val_mse: 3.5915e-04\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.0039 - mse: 3.6031e-04 - val_loss: 5.0034 - val_mse: 3.5848e-04\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.9869 - mse: 3.5970e-04 - val_loss: 4.9878 - val_mse: 3.5787e-04\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.9718 - mse: 3.5914e-04 - val_loss: 4.9742 - val_mse: 3.5733e-04\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.9586 - mse: 3.5864e-04 - val_loss: 4.9621 - val_mse: 3.5683e-04\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.9468 - mse: 3.5820e-04 - val_loss: 4.9517 - val_mse: 3.5639e-04\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.9366 - mse: 3.5780e-04 - val_loss: 4.9426 - val_mse: 3.5601e-04\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.9275 - mse: 3.5746e-04 - val_loss: 4.9346 - val_mse: 3.5567e-04\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.9196 - mse: 3.5716e-04 - val_loss: 4.9277 - val_mse: 3.5538e-04\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.9125 - mse: 3.5690e-04 - val_loss: 4.9216 - val_mse: 3.5513e-04\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.9063 - mse: 3.5668e-04 - val_loss: 4.9164 - val_mse: 3.5491e-04\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.9008 - mse: 3.5650e-04 - val_loss: 4.9118 - val_mse: 3.5475e-04\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8959 - mse: 3.5635e-04 - val_loss: 4.9078 - val_mse: 3.5460e-04\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8915 - mse: 3.5622e-04 - val_loss: 4.9042 - val_mse: 3.5448e-04\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8875 - mse: 3.5611e-04 - val_loss: 4.9011 - val_mse: 3.5439e-04\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8839 - mse: 3.5602e-04 - val_loss: 4.8984 - val_mse: 3.5432e-04\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8807 - mse: 3.5595e-04 - val_loss: 4.8960 - val_mse: 3.5426e-04\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8777 - mse: 3.5588e-04 - val_loss: 4.8939 - val_mse: 3.5421e-04\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8750 - mse: 3.5582e-04 - val_loss: 4.8919 - val_mse: 3.5417e-04\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8724 - mse: 3.5578e-04 - val_loss: 4.8901 - val_mse: 3.5414e-04\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8701 - mse: 3.5573e-04 - val_loss: 4.8886 - val_mse: 3.5412e-04\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8678 - mse: 3.5569e-04 - val_loss: 4.8874 - val_mse: 3.5411e-04\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8658 - mse: 3.5566e-04 - val_loss: 4.8861 - val_mse: 3.5409e-04\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8638 - mse: 3.5562e-04 - val_loss: 4.8850 - val_mse: 3.5409e-04\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8620 - mse: 3.5559e-04 - val_loss: 4.8839 - val_mse: 3.5408e-04\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 936us/step - loss: 4.8602 - mse: 3.5556e-04 - val_loss: 4.8829 - val_mse: 3.5407e-04\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.8586 - mse: 3.5553e-04 - val_loss: 4.8821 - val_mse: 3.5406e-04\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8570 - mse: 3.5550e-04 - val_loss: 4.8814 - val_mse: 3.5407e-04\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8555 - mse: 3.5548e-04 - val_loss: 4.8807 - val_mse: 3.5407e-04\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8540 - mse: 3.5545e-04 - val_loss: 4.8800 - val_mse: 3.5406e-04\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8527 - mse: 3.5542e-04 - val_loss: 4.8795 - val_mse: 3.5407e-04\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8513 - mse: 3.5539e-04 - val_loss: 4.8788 - val_mse: 3.5407e-04\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8501 - mse: 3.5537e-04 - val_loss: 4.8784 - val_mse: 3.5407e-04\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8488 - mse: 3.5535e-04 - val_loss: 4.8780 - val_mse: 3.5407e-04\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8476 - mse: 3.5532e-04 - val_loss: 4.8776 - val_mse: 3.5408e-04\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8464 - mse: 3.5529e-04 - val_loss: 4.8772 - val_mse: 3.5407e-04\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8453 - mse: 3.5527e-04 - val_loss: 4.8768 - val_mse: 3.5407e-04\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8442 - mse: 3.5525e-04 - val_loss: 4.8765 - val_mse: 3.5408e-04\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8432 - mse: 3.5522e-04 - val_loss: 4.8762 - val_mse: 3.5407e-04\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8422 - mse: 3.5520e-04 - val_loss: 4.8760 - val_mse: 3.5408e-04\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8412 - mse: 3.5518e-04 - val_loss: 4.8757 - val_mse: 3.5408e-04\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8402 - mse: 3.5515e-04 - val_loss: 4.8756 - val_mse: 3.5408e-04\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8392 - mse: 3.5513e-04 - val_loss: 4.8754 - val_mse: 3.5409e-04\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8383 - mse: 3.5511e-04 - val_loss: 4.8753 - val_mse: 3.5410e-04\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8374 - mse: 3.5509e-04 - val_loss: 4.8752 - val_mse: 3.5410e-04\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8365 - mse: 3.5506e-04 - val_loss: 4.8750 - val_mse: 3.5410e-04\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8357 - mse: 3.5504e-04 - val_loss: 4.8749 - val_mse: 3.5410e-04\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8348 - mse: 3.5502e-04 - val_loss: 4.8749 - val_mse: 3.5411e-04\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8340 - mse: 3.5500e-04 - val_loss: 4.8748 - val_mse: 3.5411e-04\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8331 - mse: 3.5498e-04 - val_loss: 4.8747 - val_mse: 3.5412e-04\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8323 - mse: 3.5495e-04 - val_loss: 4.8747 - val_mse: 3.5412e-04\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8316 - mse: 3.5493e-04 - val_loss: 4.8746 - val_mse: 3.5412e-04\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8308 - mse: 3.5491e-04 - val_loss: 4.8746 - val_mse: 3.5412e-04\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8300 - mse: 3.5489e-04 - val_loss: 4.8746 - val_mse: 3.5413e-04\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8292 - mse: 3.5487e-04 - val_loss: 4.8746 - val_mse: 3.5413e-04\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8285 - mse: 3.5485e-04 - val_loss: 4.8745 - val_mse: 3.5413e-04\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8277 - mse: 3.5482e-04 - val_loss: 4.8746 - val_mse: 3.5414e-04\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8270 - mse: 3.5481e-04 - val_loss: 4.8746 - val_mse: 3.5414e-04\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8263 - mse: 3.5479e-04 - val_loss: 4.8747 - val_mse: 3.5415e-04\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8256 - mse: 3.5476e-04 - val_loss: 4.8747 - val_mse: 3.5416e-04\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8249 - mse: 3.5474e-04 - val_loss: 4.8747 - val_mse: 3.5416e-04\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8242 - mse: 3.5472e-04 - val_loss: 4.8748 - val_mse: 3.5416e-04\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8235 - mse: 3.5470e-04 - val_loss: 4.8748 - val_mse: 3.5417e-04\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8228 - mse: 3.5469e-04 - val_loss: 4.8749 - val_mse: 3.5417e-04\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 876us/step - loss: 4.8221 - mse: 3.5466e-04 - val_loss: 4.8750 - val_mse: 3.5417e-04\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8215 - mse: 3.5464e-04 - val_loss: 4.8750 - val_mse: 3.5418e-04\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8208 - mse: 3.5462e-04 - val_loss: 4.8751 - val_mse: 3.5418e-04\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8201 - mse: 3.5460e-04 - val_loss: 4.8752 - val_mse: 3.5420e-04\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8195 - mse: 3.5458e-04 - val_loss: 4.8752 - val_mse: 3.5419e-04\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8188 - mse: 3.5456e-04 - val_loss: 4.8753 - val_mse: 3.5419e-04\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8182 - mse: 3.5454e-04 - val_loss: 4.8754 - val_mse: 3.5420e-04\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8176 - mse: 3.5453e-04 - val_loss: 4.8755 - val_mse: 3.5421e-04\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8169 - mse: 3.5450e-04 - val_loss: 4.8757 - val_mse: 3.5421e-04\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8163 - mse: 3.5448e-04 - val_loss: 4.8756 - val_mse: 3.5421e-04\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8157 - mse: 3.5447e-04 - val_loss: 4.8758 - val_mse: 3.5422e-04\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8150 - mse: 3.5445e-04 - val_loss: 4.8759 - val_mse: 3.5422e-04\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8144 - mse: 3.5443e-04 - val_loss: 4.8761 - val_mse: 3.5424e-04\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8138 - mse: 3.5441e-04 - val_loss: 4.8762 - val_mse: 3.5424e-04\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8132 - mse: 3.5439e-04 - val_loss: 4.8762 - val_mse: 3.5424e-04\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8126 - mse: 3.5437e-04 - val_loss: 4.8764 - val_mse: 3.5424e-04\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8120 - mse: 3.5435e-04 - val_loss: 4.8765 - val_mse: 3.5425e-04\n",
      "VAE 180 85\n",
      "(3807, 180) (423, 180)\n",
      "(3807, 536) (423, 536)\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 6.2217 - mse: 3.7992e-04 - val_loss: 6.1583 - val_mse: 3.7795e-04\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 6.1003 - mse: 3.7897e-04 - val_loss: 6.0415 - val_mse: 3.7698e-04\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.9870 - mse: 3.7797e-04 - val_loss: 5.9324 - val_mse: 3.7597e-04\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.8815 - mse: 3.7694e-04 - val_loss: 5.8311 - val_mse: 3.7493e-04\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.7834 - mse: 3.7588e-04 - val_loss: 5.7372 - val_mse: 3.7385e-04\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.6926 - mse: 3.7479e-04 - val_loss: 5.6507 - val_mse: 3.7275e-04\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.6089 - mse: 3.7368e-04 - val_loss: 5.5712 - val_mse: 3.7165e-04\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 5.5320 - mse: 3.7255e-04 - val_loss: 5.4986 - val_mse: 3.7053e-04\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.4616 - mse: 3.7143e-04 - val_loss: 5.4319 - val_mse: 3.6941e-04\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.3973 - mse: 3.7031e-04 - val_loss: 5.3716 - val_mse: 3.6831e-04\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.3388 - mse: 3.6920e-04 - val_loss: 5.3167 - val_mse: 3.6721e-04\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.2857 - mse: 3.6811e-04 - val_loss: 5.2669 - val_mse: 3.6614e-04\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.2376 - mse: 3.6704e-04 - val_loss: 5.2222 - val_mse: 3.6509e-04\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.1942 - mse: 3.6600e-04 - val_loss: 5.1820 - val_mse: 3.6407e-04\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 1ms/step - loss: 5.1551 - mse: 3.6500e-04 - val_loss: 5.1457 - val_mse: 3.6309e-04\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.1200 - mse: 3.6404e-04 - val_loss: 5.1134 - val_mse: 3.6215e-04\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.0886 - mse: 3.6313e-04 - val_loss: 5.0845 - val_mse: 3.6126e-04\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.0606 - mse: 3.6228e-04 - val_loss: 5.0589 - val_mse: 3.6042e-04\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.0356 - mse: 3.6147e-04 - val_loss: 5.0363 - val_mse: 3.5963e-04\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.0134 - mse: 3.6072e-04 - val_loss: 5.0162 - val_mse: 3.5890e-04\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.9938 - mse: 3.6003e-04 - val_loss: 4.9984 - val_mse: 3.5822e-04\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.9763 - mse: 3.5940e-04 - val_loss: 4.9829 - val_mse: 3.5760e-04\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.9609 - mse: 3.5883e-04 - val_loss: 4.9692 - val_mse: 3.5704e-04\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.9472 - mse: 3.5831e-04 - val_loss: 4.9571 - val_mse: 3.5653e-04\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.9352 - mse: 3.5785e-04 - val_loss: 4.9467 - val_mse: 3.5608e-04\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.9246 - mse: 3.5745e-04 - val_loss: 4.9376 - val_mse: 3.5569e-04\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.9152 - mse: 3.5709e-04 - val_loss: 4.9295 - val_mse: 3.5533e-04\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.9069 - mse: 3.5678e-04 - val_loss: 4.9225 - val_mse: 3.5504e-04\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8994 - mse: 3.5651e-04 - val_loss: 4.9165 - val_mse: 3.5478e-04\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8928 - mse: 3.5628e-04 - val_loss: 4.9113 - val_mse: 3.5457e-04\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8870 - mse: 3.5609e-04 - val_loss: 4.9066 - val_mse: 3.5438e-04\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8817 - mse: 3.5592e-04 - val_loss: 4.9026 - val_mse: 3.5423e-04\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8769 - mse: 3.5578e-04 - val_loss: 4.8989 - val_mse: 3.5410e-04\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8725 - mse: 3.5565e-04 - val_loss: 4.8957 - val_mse: 3.5400e-04\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8686 - mse: 3.5555e-04 - val_loss: 4.8930 - val_mse: 3.5392e-04\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8649 - mse: 3.5546e-04 - val_loss: 4.8905 - val_mse: 3.5384e-04\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8616 - mse: 3.5538e-04 - val_loss: 4.8883 - val_mse: 3.5379e-04\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8584 - mse: 3.5531e-04 - val_loss: 4.8864 - val_mse: 3.5376e-04\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8555 - mse: 3.5525e-04 - val_loss: 4.8845 - val_mse: 3.5371e-04\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 979us/step - loss: 4.8527 - mse: 3.5519e-04 - val_loss: 4.8830 - val_mse: 3.5369e-04\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.8502 - mse: 3.5514e-04 - val_loss: 4.8815 - val_mse: 3.5367e-04\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8477 - mse: 3.5509e-04 - val_loss: 4.8803 - val_mse: 3.5365e-04\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8454 - mse: 3.5504e-04 - val_loss: 4.8790 - val_mse: 3.5363e-04\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8431 - mse: 3.5500e-04 - val_loss: 4.8780 - val_mse: 3.5362e-04\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.8410 - mse: 3.5495e-04 - val_loss: 4.8770 - val_mse: 3.5361e-04\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8390 - mse: 3.5491e-04 - val_loss: 4.8762 - val_mse: 3.5361e-04\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8370 - mse: 3.5487e-04 - val_loss: 4.8753 - val_mse: 3.5359e-04\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8351 - mse: 3.5483e-04 - val_loss: 4.8745 - val_mse: 3.5359e-04\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8333 - mse: 3.5479e-04 - val_loss: 4.8738 - val_mse: 3.5358e-04\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8316 - mse: 3.5475e-04 - val_loss: 4.8733 - val_mse: 3.5358e-04\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8299 - mse: 3.5471e-04 - val_loss: 4.8727 - val_mse: 3.5357e-04\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8282 - mse: 3.5468e-04 - val_loss: 4.8722 - val_mse: 3.5357e-04\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8266 - mse: 3.5464e-04 - val_loss: 4.8717 - val_mse: 3.5357e-04\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8250 - mse: 3.5460e-04 - val_loss: 4.8712 - val_mse: 3.5356e-04\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8235 - mse: 3.5456e-04 - val_loss: 4.8709 - val_mse: 3.5357e-04\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8221 - mse: 3.5453e-04 - val_loss: 4.8705 - val_mse: 3.5357e-04\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8206 - mse: 3.5449e-04 - val_loss: 4.8701 - val_mse: 3.5356e-04\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8192 - mse: 3.5445e-04 - val_loss: 4.8698 - val_mse: 3.5356e-04\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8178 - mse: 3.5442e-04 - val_loss: 4.8695 - val_mse: 3.5356e-04\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8165 - mse: 3.5438e-04 - val_loss: 4.8693 - val_mse: 3.5356e-04\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8152 - mse: 3.5435e-04 - val_loss: 4.8691 - val_mse: 3.5356e-04\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8139 - mse: 3.5431e-04 - val_loss: 4.8689 - val_mse: 3.5356e-04\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.8126 - mse: 3.5428e-04 - val_loss: 4.8687 - val_mse: 3.5355e-04\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8113 - mse: 3.5424e-04 - val_loss: 4.8686 - val_mse: 3.5356e-04\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8101 - mse: 3.5421e-04 - val_loss: 4.8685 - val_mse: 3.5356e-04\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8089 - mse: 3.5418e-04 - val_loss: 4.8683 - val_mse: 3.5356e-04\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8077 - mse: 3.5414e-04 - val_loss: 4.8683 - val_mse: 3.5356e-04\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8065 - mse: 3.5411e-04 - val_loss: 4.8682 - val_mse: 3.5356e-04\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8054 - mse: 3.5408e-04 - val_loss: 4.8681 - val_mse: 3.5356e-04\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8042 - mse: 3.5404e-04 - val_loss: 4.8680 - val_mse: 3.5356e-04\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8031 - mse: 3.5401e-04 - val_loss: 4.8680 - val_mse: 3.5356e-04\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8020 - mse: 3.5398e-04 - val_loss: 4.8679 - val_mse: 3.5356e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8009 - mse: 3.5395e-04 - val_loss: 4.8679 - val_mse: 3.5356e-04\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7998 - mse: 3.5391e-04 - val_loss: 4.8679 - val_mse: 3.5356e-04\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7988 - mse: 3.5388e-04 - val_loss: 4.8679 - val_mse: 3.5356e-04\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7977 - mse: 3.5385e-04 - val_loss: 4.8680 - val_mse: 3.5357e-04\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7966 - mse: 3.5382e-04 - val_loss: 4.8679 - val_mse: 3.5357e-04\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.7956 - mse: 3.5379e-04 - val_loss: 4.8680 - val_mse: 3.5357e-04\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7945 - mse: 3.5375e-04 - val_loss: 4.8681 - val_mse: 3.5357e-04\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7936 - mse: 3.5373e-04 - val_loss: 4.8681 - val_mse: 3.5358e-04\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7926 - mse: 3.5370e-04 - val_loss: 4.8681 - val_mse: 3.5357e-04\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.7915 - mse: 3.5366e-04 - val_loss: 4.8682 - val_mse: 3.5357e-04\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7906 - mse: 3.5363e-04 - val_loss: 4.8683 - val_mse: 3.5358e-04\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7896 - mse: 3.5360e-04 - val_loss: 4.8684 - val_mse: 3.5358e-04\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7886 - mse: 3.5357e-04 - val_loss: 4.8684 - val_mse: 3.5358e-04\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7876 - mse: 3.5354e-04 - val_loss: 4.8684 - val_mse: 3.5358e-04\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7867 - mse: 3.5351e-04 - val_loss: 4.8686 - val_mse: 3.5359e-04\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7857 - mse: 3.5348e-04 - val_loss: 4.8687 - val_mse: 3.5359e-04\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7848 - mse: 3.5345e-04 - val_loss: 4.8688 - val_mse: 3.5359e-04\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7838 - mse: 3.5342e-04 - val_loss: 4.8689 - val_mse: 3.5359e-04\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7829 - mse: 3.5339e-04 - val_loss: 4.8690 - val_mse: 3.5359e-04\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7819 - mse: 3.5336e-04 - val_loss: 4.8692 - val_mse: 3.5360e-04\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7810 - mse: 3.5333e-04 - val_loss: 4.8691 - val_mse: 3.5360e-04\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7801 - mse: 3.5330e-04 - val_loss: 4.8693 - val_mse: 3.5360e-04\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7792 - mse: 3.5327e-04 - val_loss: 4.8694 - val_mse: 3.5360e-04\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7783 - mse: 3.5324e-04 - val_loss: 4.8695 - val_mse: 3.5360e-04\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.7774 - mse: 3.5321e-04 - val_loss: 4.8697 - val_mse: 3.5360e-04\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7765 - mse: 3.5318e-04 - val_loss: 4.8700 - val_mse: 3.5362e-04\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7756 - mse: 3.5315e-04 - val_loss: 4.8700 - val_mse: 3.5361e-04\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7747 - mse: 3.5312e-04 - val_loss: 4.8702 - val_mse: 3.5362e-04\n",
      "VAE 237 90\n",
      "(3807, 237) (423, 237)\n",
      "(3807, 536) (423, 536)\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 6.2217 - mse: 3.7992e-04 - val_loss: 6.1578 - val_mse: 3.7795e-04\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6.0998 - mse: 3.7896e-04 - val_loss: 6.0407 - val_mse: 3.7698e-04\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.9857 - mse: 3.7796e-04 - val_loss: 5.9315 - val_mse: 3.7596e-04\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.8794 - mse: 3.7692e-04 - val_loss: 5.8299 - val_mse: 3.7491e-04\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.7805 - mse: 3.7585e-04 - val_loss: 5.7361 - val_mse: 3.7384e-04\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.6890 - mse: 3.7475e-04 - val_loss: 5.6494 - val_mse: 3.7274e-04\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.6045 - mse: 3.7362e-04 - val_loss: 5.5697 - val_mse: 3.7162e-04\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.5268 - mse: 3.7249e-04 - val_loss: 5.4967 - val_mse: 3.7050e-04\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.4556 - mse: 3.7135e-04 - val_loss: 5.4300 - val_mse: 3.6938e-04\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.3906 - mse: 3.7021e-04 - val_loss: 5.3693 - val_mse: 3.6826e-04\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.3313 - mse: 3.6908e-04 - val_loss: 5.3142 - val_mse: 3.6716e-04\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.2774 - mse: 3.6796e-04 - val_loss: 5.2645 - val_mse: 3.6608e-04\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 5.2285 - mse: 3.6687e-04 - val_loss: 5.2196 - val_mse: 3.6503e-04\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.1844 - mse: 3.6581e-04 - val_loss: 5.1791 - val_mse: 3.6400e-04\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.1446 - mse: 3.6478e-04 - val_loss: 5.1428 - val_mse: 3.6302e-04\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.1087 - mse: 3.6380e-04 - val_loss: 5.1105 - val_mse: 3.6207e-04\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 5.0766 - mse: 3.6286e-04 - val_loss: 5.0815 - val_mse: 3.6117e-04\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.0479 - mse: 3.6198e-04 - val_loss: 5.0559 - val_mse: 3.6032e-04\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.0222 - mse: 3.6114e-04 - val_loss: 5.0330 - val_mse: 3.5953e-04\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.9993 - mse: 3.6037e-04 - val_loss: 5.0129 - val_mse: 3.5879e-04\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.9789 - mse: 3.5965e-04 - val_loss: 4.9951 - val_mse: 3.5810e-04\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.9608 - mse: 3.5898e-04 - val_loss: 4.9794 - val_mse: 3.5747e-04\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.9446 - mse: 3.5838e-04 - val_loss: 4.9657 - val_mse: 3.5691e-04\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.9303 - mse: 3.5783e-04 - val_loss: 4.9535 - val_mse: 3.5639e-04\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.9176 - mse: 3.5734e-04 - val_loss: 4.9431 - val_mse: 3.5593e-04\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.9062 - mse: 3.5690e-04 - val_loss: 4.9338 - val_mse: 3.5553e-04\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8961 - mse: 3.5651e-04 - val_loss: 4.9258 - val_mse: 3.5517e-04\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8871 - mse: 3.5616e-04 - val_loss: 4.9188 - val_mse: 3.5487e-04\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8790 - mse: 3.5586e-04 - val_loss: 4.9127 - val_mse: 3.5461e-04\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8718 - mse: 3.5560e-04 - val_loss: 4.9073 - val_mse: 3.5439e-04\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8652 - mse: 3.5537e-04 - val_loss: 4.9026 - val_mse: 3.5419e-04\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8592 - mse: 3.5517e-04 - val_loss: 4.8985 - val_mse: 3.5404e-04\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8538 - mse: 3.5500e-04 - val_loss: 4.8949 - val_mse: 3.5391e-04\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8488 - mse: 3.5485e-04 - val_loss: 4.8917 - val_mse: 3.5380e-04\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8442 - mse: 3.5472e-04 - val_loss: 4.8890 - val_mse: 3.5372e-04\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8399 - mse: 3.5460e-04 - val_loss: 4.8865 - val_mse: 3.5365e-04\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8359 - mse: 3.5449e-04 - val_loss: 4.8842 - val_mse: 3.5360e-04\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8321 - mse: 3.5439e-04 - val_loss: 4.8822 - val_mse: 3.5355e-04\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8285 - mse: 3.5431e-04 - val_loss: 4.8806 - val_mse: 3.5351e-04\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8251 - mse: 3.5422e-04 - val_loss: 4.8789 - val_mse: 3.5348e-04\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8219 - mse: 3.5414e-04 - val_loss: 4.8775 - val_mse: 3.5346e-04\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8188 - mse: 3.5407e-04 - val_loss: 4.8762 - val_mse: 3.5343e-04\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8159 - mse: 3.5400e-04 - val_loss: 4.8750 - val_mse: 3.5342e-04\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8131 - mse: 3.5393e-04 - val_loss: 4.8739 - val_mse: 3.5340e-04\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8103 - mse: 3.5386e-04 - val_loss: 4.8730 - val_mse: 3.5339e-04\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8077 - mse: 3.5379e-04 - val_loss: 4.8722 - val_mse: 3.5339e-04\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8051 - mse: 3.5373e-04 - val_loss: 4.8714 - val_mse: 3.5338e-04\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8026 - mse: 3.5366e-04 - val_loss: 4.8706 - val_mse: 3.5337e-04\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8002 - mse: 3.5360e-04 - val_loss: 4.8700 - val_mse: 3.5336e-04\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.7978 - mse: 3.5353e-04 - val_loss: 4.8694 - val_mse: 3.5335e-04\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7955 - mse: 3.5347e-04 - val_loss: 4.8688 - val_mse: 3.5335e-04\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7933 - mse: 3.5341e-04 - val_loss: 4.8683 - val_mse: 3.5334e-04\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7911 - mse: 3.5335e-04 - val_loss: 4.8679 - val_mse: 3.5334e-04\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7890 - mse: 3.5329e-04 - val_loss: 4.8675 - val_mse: 3.5334e-04\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7869 - mse: 3.5323e-04 - val_loss: 4.8672 - val_mse: 3.5334e-04\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7848 - mse: 3.5317e-04 - val_loss: 4.8669 - val_mse: 3.5334e-04\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7828 - mse: 3.5311e-04 - val_loss: 4.8666 - val_mse: 3.5333e-04\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7809 - mse: 3.5305e-04 - val_loss: 4.8663 - val_mse: 3.5333e-04\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7789 - mse: 3.5300e-04 - val_loss: 4.8661 - val_mse: 3.5333e-04\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7770 - mse: 3.5294e-04 - val_loss: 4.8660 - val_mse: 3.5333e-04\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7751 - mse: 3.5288e-04 - val_loss: 4.8659 - val_mse: 3.5334e-04\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7733 - mse: 3.5283e-04 - val_loss: 4.8657 - val_mse: 3.5333e-04\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7714 - mse: 3.5277e-04 - val_loss: 4.8655 - val_mse: 3.5333e-04\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7696 - mse: 3.5271e-04 - val_loss: 4.8655 - val_mse: 3.5333e-04\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7678 - mse: 3.5266e-04 - val_loss: 4.8655 - val_mse: 3.5333e-04\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7661 - mse: 3.5260e-04 - val_loss: 4.8654 - val_mse: 3.5333e-04\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7644 - mse: 3.5255e-04 - val_loss: 4.8655 - val_mse: 3.5334e-04\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7627 - mse: 3.5249e-04 - val_loss: 4.8654 - val_mse: 3.5333e-04\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7609 - mse: 3.5244e-04 - val_loss: 4.8654 - val_mse: 3.5334e-04\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7593 - mse: 3.5238e-04 - val_loss: 4.8655 - val_mse: 3.5334e-04\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7576 - mse: 3.5233e-04 - val_loss: 4.8656 - val_mse: 3.5334e-04\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.7560 - mse: 3.5227e-04 - val_loss: 4.8656 - val_mse: 3.5334e-04\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7544 - mse: 3.5222e-04 - val_loss: 4.8656 - val_mse: 3.5334e-04\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7528 - mse: 3.5217e-04 - val_loss: 4.8657 - val_mse: 3.5335e-04\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7512 - mse: 3.5211e-04 - val_loss: 4.8658 - val_mse: 3.5335e-04\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7496 - mse: 3.5206e-04 - val_loss: 4.8661 - val_mse: 3.5336e-04\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7480 - mse: 3.5201e-04 - val_loss: 4.8661 - val_mse: 3.5335e-04\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7465 - mse: 3.5196e-04 - val_loss: 4.8662 - val_mse: 3.5336e-04\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7450 - mse: 3.5190e-04 - val_loss: 4.8664 - val_mse: 3.5336e-04\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7434 - mse: 3.5185e-04 - val_loss: 4.8665 - val_mse: 3.5336e-04\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7419 - mse: 3.5180e-04 - val_loss: 4.8667 - val_mse: 3.5337e-04\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7404 - mse: 3.5174e-04 - val_loss: 4.8669 - val_mse: 3.5338e-04\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7389 - mse: 3.5169e-04 - val_loss: 4.8671 - val_mse: 3.5338e-04\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7374 - mse: 3.5164e-04 - val_loss: 4.8672 - val_mse: 3.5338e-04\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7360 - mse: 3.5159e-04 - val_loss: 4.8675 - val_mse: 3.5339e-04\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 972us/step - loss: 4.7345 - mse: 3.5154e-04 - val_loss: 4.8677 - val_mse: 3.5339e-04\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.7331 - mse: 3.5149e-04 - val_loss: 4.8679 - val_mse: 3.5340e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7316 - mse: 3.5144e-04 - val_loss: 4.8680 - val_mse: 3.5339e-04\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7302 - mse: 3.5139e-04 - val_loss: 4.8684 - val_mse: 3.5341e-04\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7287 - mse: 3.5134e-04 - val_loss: 4.8686 - val_mse: 3.5341e-04\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7274 - mse: 3.5129e-04 - val_loss: 4.8688 - val_mse: 3.5341e-04\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7259 - mse: 3.5123e-04 - val_loss: 4.8691 - val_mse: 3.5342e-04\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7245 - mse: 3.5118e-04 - val_loss: 4.8692 - val_mse: 3.5342e-04\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7231 - mse: 3.5113e-04 - val_loss: 4.8696 - val_mse: 3.5343e-04\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7218 - mse: 3.5108e-04 - val_loss: 4.8699 - val_mse: 3.5344e-04\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7204 - mse: 3.5103e-04 - val_loss: 4.8701 - val_mse: 3.5344e-04\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7190 - mse: 3.5098e-04 - val_loss: 4.8704 - val_mse: 3.5345e-04\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7177 - mse: 3.5094e-04 - val_loss: 4.8706 - val_mse: 3.5345e-04\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7163 - mse: 3.5089e-04 - val_loss: 4.8710 - val_mse: 3.5346e-04\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7150 - mse: 3.5084e-04 - val_loss: 4.8713 - val_mse: 3.5347e-04\n",
      "VAE 355 95\n",
      "(3807, 355) (423, 355)\n",
      "(3807, 536) (423, 536)\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 6.2221 - mse: 3.7992e-04 - val_loss: 6.1580 - val_mse: 3.7795e-04\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6.0978 - mse: 3.7895e-04 - val_loss: 6.0408 - val_mse: 3.7697e-04\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 991us/step - loss: 5.9817 - mse: 3.7793e-04 - val_loss: 5.9316 - val_mse: 3.7596e-04\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 5.8732 - mse: 3.7686e-04 - val_loss: 5.8298 - val_mse: 3.7491e-04\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.7723 - mse: 3.7576e-04 - val_loss: 5.7356 - val_mse: 3.7383e-04\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.6787 - mse: 3.7462e-04 - val_loss: 5.6488 - val_mse: 3.7272e-04\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.5921 - mse: 3.7346e-04 - val_loss: 5.5687 - val_mse: 3.7160e-04\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.5124 - mse: 3.7228e-04 - val_loss: 5.4953 - val_mse: 3.7047e-04\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.4391 - mse: 3.7109e-04 - val_loss: 5.4286 - val_mse: 3.6934e-04\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.3721 - mse: 3.6990e-04 - val_loss: 5.3676 - val_mse: 3.6821e-04\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.3108 - mse: 3.6872e-04 - val_loss: 5.3126 - val_mse: 3.6711e-04\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.2550 - mse: 3.6755e-04 - val_loss: 5.2624 - val_mse: 3.6601e-04\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.2042 - mse: 3.6639e-04 - val_loss: 5.2173 - val_mse: 3.6494e-04\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.1581 - mse: 3.6527e-04 - val_loss: 5.1767 - val_mse: 3.6390e-04\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.1164 - mse: 3.6417e-04 - val_loss: 5.1403 - val_mse: 3.6290e-04\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.0787 - mse: 3.6312e-04 - val_loss: 5.1078 - val_mse: 3.6194e-04\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.0448 - mse: 3.6211e-04 - val_loss: 5.0785 - val_mse: 3.6102e-04\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 5.0142 - mse: 3.6115e-04 - val_loss: 5.0528 - val_mse: 3.6016e-04\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.9867 - mse: 3.6023e-04 - val_loss: 5.0299 - val_mse: 3.5935e-04\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.9620 - mse: 3.5938e-04 - val_loss: 5.0095 - val_mse: 3.5858e-04\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.9398 - mse: 3.5858e-04 - val_loss: 4.9916 - val_mse: 3.5789e-04\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.9199 - mse: 3.5783e-04 - val_loss: 4.9758 - val_mse: 3.5724e-04\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.9020 - mse: 3.5715e-04 - val_loss: 4.9619 - val_mse: 3.5665e-04\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8859 - mse: 3.5652e-04 - val_loss: 4.9498 - val_mse: 3.5611e-04\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8714 - mse: 3.5594e-04 - val_loss: 4.9391 - val_mse: 3.5564e-04\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8583 - mse: 3.5542e-04 - val_loss: 4.9299 - val_mse: 3.5523e-04\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8465 - mse: 3.5495e-04 - val_loss: 4.9216 - val_mse: 3.5484e-04\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8357 - mse: 3.5452e-04 - val_loss: 4.9145 - val_mse: 3.5452e-04\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8259 - mse: 3.5414e-04 - val_loss: 4.9084 - val_mse: 3.5424e-04\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8169 - mse: 3.5380e-04 - val_loss: 4.9029 - val_mse: 3.5399e-04\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8087 - mse: 3.5350e-04 - val_loss: 4.8983 - val_mse: 3.5380e-04\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.8011 - mse: 3.5322e-04 - val_loss: 4.8941 - val_mse: 3.5362e-04\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7940 - mse: 3.5297e-04 - val_loss: 4.8905 - val_mse: 3.5347e-04\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7873 - mse: 3.5274e-04 - val_loss: 4.8873 - val_mse: 3.5336e-04\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7810 - mse: 3.5253e-04 - val_loss: 4.8846 - val_mse: 3.5326e-04\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7751 - mse: 3.5234e-04 - val_loss: 4.8822 - val_mse: 3.5318e-04\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7694 - mse: 3.5216e-04 - val_loss: 4.8798 - val_mse: 3.5310e-04\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.7640 - mse: 3.5199e-04 - val_loss: 4.8781 - val_mse: 3.5306e-04\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7589 - mse: 3.5182e-04 - val_loss: 4.8763 - val_mse: 3.5300e-04\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7538 - mse: 3.5167e-04 - val_loss: 4.8748 - val_mse: 3.5297e-04\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7490 - mse: 3.5151e-04 - val_loss: 4.8734 - val_mse: 3.5293e-04\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7444 - mse: 3.5136e-04 - val_loss: 4.8722 - val_mse: 3.5290e-04\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7398 - mse: 3.5121e-04 - val_loss: 4.8712 - val_mse: 3.5288e-04\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7354 - mse: 3.5107e-04 - val_loss: 4.8702 - val_mse: 3.5285e-04\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7311 - mse: 3.5093e-04 - val_loss: 4.8693 - val_mse: 3.5284e-04\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7269 - mse: 3.5079e-04 - val_loss: 4.8686 - val_mse: 3.5282e-04\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7228 - mse: 3.5065e-04 - val_loss: 4.8680 - val_mse: 3.5280e-04\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7188 - mse: 3.5051e-04 - val_loss: 4.8674 - val_mse: 3.5279e-04\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7148 - mse: 3.5038e-04 - val_loss: 4.8668 - val_mse: 3.5277e-04\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7109 - mse: 3.5024e-04 - val_loss: 4.8664 - val_mse: 3.5277e-04\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7072 - mse: 3.5011e-04 - val_loss: 4.8661 - val_mse: 3.5276e-04\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7034 - mse: 3.4997e-04 - val_loss: 4.8658 - val_mse: 3.5275e-04\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.6997 - mse: 3.4984e-04 - val_loss: 4.8655 - val_mse: 3.5274e-04\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.6961 - mse: 3.4971e-04 - val_loss: 4.8653 - val_mse: 3.5274e-04\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.6925 - mse: 3.4957e-04 - val_loss: 4.8652 - val_mse: 3.5273e-04\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.6891 - mse: 3.4944e-04 - val_loss: 4.8652 - val_mse: 3.5274e-04\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.6856 - mse: 3.4931e-04 - val_loss: 4.8651 - val_mse: 3.5274e-04\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.6822 - mse: 3.4918e-04 - val_loss: 4.8651 - val_mse: 3.5274e-04\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.6788 - mse: 3.4905e-04 - val_loss: 4.8651 - val_mse: 3.5273e-04\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.6755 - mse: 3.4892e-04 - val_loss: 4.8652 - val_mse: 3.5273e-04\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.6722 - mse: 3.4878e-04 - val_loss: 4.8652 - val_mse: 3.5273e-04\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.6689 - mse: 3.4865e-04 - val_loss: 4.8654 - val_mse: 3.5273e-04\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.6657 - mse: 3.4852e-04 - val_loss: 4.8656 - val_mse: 3.5273e-04\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.6625 - mse: 3.4839e-04 - val_loss: 4.8657 - val_mse: 3.5273e-04\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.6593 - mse: 3.4826e-04 - val_loss: 4.8660 - val_mse: 3.5274e-04\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.6562 - mse: 3.4812e-04 - val_loss: 4.8662 - val_mse: 3.5273e-04\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.6531 - mse: 3.4799e-04 - val_loss: 4.8666 - val_mse: 3.5275e-04\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.6501 - mse: 3.4786e-04 - val_loss: 4.8669 - val_mse: 3.5275e-04\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.6470 - mse: 3.4773e-04 - val_loss: 4.8671 - val_mse: 3.5275e-04\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.6440 - mse: 3.4760e-04 - val_loss: 4.8674 - val_mse: 3.5275e-04\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.6410 - mse: 3.4747e-04 - val_loss: 4.8678 - val_mse: 3.5276e-04\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.6380 - mse: 3.4734e-04 - val_loss: 4.8682 - val_mse: 3.5277e-04\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.6351 - mse: 3.4720e-04 - val_loss: 4.8686 - val_mse: 3.5277e-04\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.6322 - mse: 3.4707e-04 - val_loss: 4.8689 - val_mse: 3.5277e-04\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.6293 - mse: 3.4694e-04 - val_loss: 4.8695 - val_mse: 3.5279e-04\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.6264 - mse: 3.4681e-04 - val_loss: 4.8699 - val_mse: 3.5280e-04\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.6236 - mse: 3.4668e-04 - val_loss: 4.8704 - val_mse: 3.5281e-04\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.6208 - mse: 3.4654e-04 - val_loss: 4.8708 - val_mse: 3.5280e-04\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.6179 - mse: 3.4641e-04 - val_loss: 4.8714 - val_mse: 3.5282e-04\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.6152 - mse: 3.4628e-04 - val_loss: 4.8718 - val_mse: 3.5282e-04\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.6124 - mse: 3.4614e-04 - val_loss: 4.8725 - val_mse: 3.5285e-04\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.6096 - mse: 3.4601e-04 - val_loss: 4.8729 - val_mse: 3.5285e-04\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.6069 - mse: 3.4587e-04 - val_loss: 4.8735 - val_mse: 3.5286e-04\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.6042 - mse: 3.4574e-04 - val_loss: 4.8741 - val_mse: 3.5287e-04\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.6015 - mse: 3.4561e-04 - val_loss: 4.8747 - val_mse: 3.5288e-04\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.5988 - mse: 3.4547e-04 - val_loss: 4.8752 - val_mse: 3.5289e-04\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.5962 - mse: 3.4534e-04 - val_loss: 4.8758 - val_mse: 3.5290e-04\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.5935 - mse: 3.4520e-04 - val_loss: 4.8765 - val_mse: 3.5292e-04\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.5909 - mse: 3.4506e-04 - val_loss: 4.8771 - val_mse: 3.5293e-04\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 985us/step - loss: 4.5883 - mse: 3.4492e-04 - val_loss: 4.8777 - val_mse: 3.5294e-04\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.5857 - mse: 3.4479e-04 - val_loss: 4.8783 - val_mse: 3.5295e-04\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.5831 - mse: 3.4465e-04 - val_loss: 4.8790 - val_mse: 3.5297e-04\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.5805 - mse: 3.4451e-04 - val_loss: 4.8797 - val_mse: 3.5298e-04\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.5780 - mse: 3.4437e-04 - val_loss: 4.8803 - val_mse: 3.5299e-04\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.5755 - mse: 3.4424e-04 - val_loss: 4.8810 - val_mse: 3.5301e-04\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.5729 - mse: 3.4409e-04 - val_loss: 4.8817 - val_mse: 3.5302e-04\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.5704 - mse: 3.4395e-04 - val_loss: 4.8825 - val_mse: 3.5304e-04\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.5679 - mse: 3.4381e-04 - val_loss: 4.8831 - val_mse: 3.5305e-04\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.5655 - mse: 3.4367e-04 - val_loss: 4.8839 - val_mse: 3.5307e-04\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.5630 - mse: 3.4353e-04 - val_loss: 4.8846 - val_mse: 3.5308e-04\n",
      "VAE 697 99\n",
      "(3807, 697) (423, 697)\n",
      "(3807, 536) (423, 536)\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 6.2228 - mse: 3.7992e-04 - val_loss: 6.1572 - val_mse: 3.7794e-04\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 2ms/step - loss: 6.0886 - mse: 3.7887e-04 - val_loss: 6.0382 - val_mse: 3.7695e-04\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 5.9628 - mse: 3.7775e-04 - val_loss: 5.9271 - val_mse: 3.7591e-04\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 5.8450 - mse: 3.7657e-04 - val_loss: 5.8238 - val_mse: 3.7483e-04\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.7349 - mse: 3.7533e-04 - val_loss: 5.7284 - val_mse: 3.7372e-04\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 5.6324 - mse: 3.7404e-04 - val_loss: 5.6402 - val_mse: 3.7258e-04\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.5370 - mse: 3.7270e-04 - val_loss: 5.5590 - val_mse: 3.7141e-04\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 5.4486 - mse: 3.7132e-04 - val_loss: 5.4849 - val_mse: 3.7024e-04\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.3667 - mse: 3.6990e-04 - val_loss: 5.4168 - val_mse: 3.6906e-04\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 5.2911 - mse: 3.6846e-04 - val_loss: 5.3550 - val_mse: 3.6788e-04\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 5.2214 - mse: 3.6700e-04 - val_loss: 5.2987 - val_mse: 3.6671e-04\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.1573 - mse: 3.6552e-04 - val_loss: 5.2480 - val_mse: 3.6556e-04\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 5.0984 - mse: 3.6405e-04 - val_loss: 5.2020 - val_mse: 3.6442e-04\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 5.0443 - mse: 3.6259e-04 - val_loss: 5.1608 - val_mse: 3.6333e-04\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.9947 - mse: 3.6113e-04 - val_loss: 5.1238 - val_mse: 3.6227e-04\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.9491 - mse: 3.5969e-04 - val_loss: 5.0907 - val_mse: 3.6125e-04\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.9074 - mse: 3.5829e-04 - val_loss: 5.0611 - val_mse: 3.6026e-04\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.8692 - mse: 3.5691e-04 - val_loss: 5.0347 - val_mse: 3.5933e-04\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.8341 - mse: 3.5557e-04 - val_loss: 5.0115 - val_mse: 3.5847e-04\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.8019 - mse: 3.5427e-04 - val_loss: 4.9910 - val_mse: 3.5766e-04\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.7723 - mse: 3.5302e-04 - val_loss: 4.9729 - val_mse: 3.5692e-04\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 4.7451 - mse: 3.5182e-04 - val_loss: 4.9572 - val_mse: 3.5624e-04\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.7199 - mse: 3.5066e-04 - val_loss: 4.9432 - val_mse: 3.5562e-04\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.6967 - mse: 3.4955e-04 - val_loss: 4.9309 - val_mse: 3.5505e-04\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.6751 - mse: 3.4849e-04 - val_loss: 4.9204 - val_mse: 3.5455e-04\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.6551 - mse: 3.4747e-04 - val_loss: 4.9112 - val_mse: 3.5412e-04\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.6362 - mse: 3.4650e-04 - val_loss: 4.9035 - val_mse: 3.5375e-04\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.6187 - mse: 3.4557e-04 - val_loss: 4.8967 - val_mse: 3.5341e-04\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.6021 - mse: 3.4468e-04 - val_loss: 4.8908 - val_mse: 3.5313e-04\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.5864 - mse: 3.4382e-04 - val_loss: 4.8859 - val_mse: 3.5291e-04\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.5715 - mse: 3.4299e-04 - val_loss: 4.8816 - val_mse: 3.5271e-04\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.5573 - mse: 3.4218e-04 - val_loss: 4.8779 - val_mse: 3.5254e-04\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.5436 - mse: 3.4140e-04 - val_loss: 4.8749 - val_mse: 3.5242e-04\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.5305 - mse: 3.4062e-04 - val_loss: 4.8723 - val_mse: 3.5231e-04\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.5179 - mse: 3.3986e-04 - val_loss: 4.8702 - val_mse: 3.5222e-04\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 4.5056 - mse: 3.3910e-04 - val_loss: 4.8683 - val_mse: 3.5215e-04\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 4.4938 - mse: 3.3835e-04 - val_loss: 4.8670 - val_mse: 3.5210e-04\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.4823 - mse: 3.3760e-04 - val_loss: 4.8659 - val_mse: 3.5206e-04\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.4710 - mse: 3.3684e-04 - val_loss: 4.8652 - val_mse: 3.5204e-04\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.4600 - mse: 3.3608e-04 - val_loss: 4.8645 - val_mse: 3.5201e-04\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.4493 - mse: 3.3531e-04 - val_loss: 4.8640 - val_mse: 3.5200e-04\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.4388 - mse: 3.3453e-04 - val_loss: 4.8639 - val_mse: 3.5199e-04\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.4285 - mse: 3.3374e-04 - val_loss: 4.8637 - val_mse: 3.5197e-04\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.4184 - mse: 3.3295e-04 - val_loss: 4.8640 - val_mse: 3.5198e-04\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.4085 - mse: 3.3214e-04 - val_loss: 4.8641 - val_mse: 3.5199e-04\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.3987 - mse: 3.3131e-04 - val_loss: 4.8646 - val_mse: 3.5199e-04\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 4.3891 - mse: 3.3048e-04 - val_loss: 4.8652 - val_mse: 3.5201e-04\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.3797 - mse: 3.2964e-04 - val_loss: 4.8659 - val_mse: 3.5202e-04\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.3704 - mse: 3.2880e-04 - val_loss: 4.8665 - val_mse: 3.5204e-04\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.3613 - mse: 3.2791e-04 - val_loss: 4.8675 - val_mse: 3.5205e-04\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.3524 - mse: 3.2704e-04 - val_loss: 4.8683 - val_mse: 3.5208e-04\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.3436 - mse: 3.2614e-04 - val_loss: 4.8693 - val_mse: 3.5209e-04\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.3348 - mse: 3.2526e-04 - val_loss: 4.8705 - val_mse: 3.5212e-04\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.3263 - mse: 3.2434e-04 - val_loss: 4.8717 - val_mse: 3.5215e-04\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.3178 - mse: 3.2343e-04 - val_loss: 4.8728 - val_mse: 3.5217e-04\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.3095 - mse: 3.2249e-04 - val_loss: 4.8742 - val_mse: 3.5221e-04\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.3013 - mse: 3.2156e-04 - val_loss: 4.8757 - val_mse: 3.5224e-04\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.2933 - mse: 3.2063e-04 - val_loss: 4.8771 - val_mse: 3.5227e-04\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.2853 - mse: 3.1967e-04 - val_loss: 4.8787 - val_mse: 3.5232e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.2774 - mse: 3.1872e-04 - val_loss: 4.8801 - val_mse: 3.5233e-04\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.2697 - mse: 3.1775e-04 - val_loss: 4.8819 - val_mse: 3.5240e-04\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.2621 - mse: 3.1678e-04 - val_loss: 4.8835 - val_mse: 3.5244e-04\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.2546 - mse: 3.1583e-04 - val_loss: 4.8851 - val_mse: 3.5248e-04\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.2472 - mse: 3.1486e-04 - val_loss: 4.8870 - val_mse: 3.5252e-04\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.2399 - mse: 3.1389e-04 - val_loss: 4.8888 - val_mse: 3.5257e-04\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.2327 - mse: 3.1294e-04 - val_loss: 4.8907 - val_mse: 3.5262e-04\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.2256 - mse: 3.1197e-04 - val_loss: 4.8927 - val_mse: 3.5268e-04\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.2185 - mse: 3.1099e-04 - val_loss: 4.8945 - val_mse: 3.5273e-04\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.2116 - mse: 3.1003e-04 - val_loss: 4.8964 - val_mse: 3.5277e-04\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.2048 - mse: 3.0908e-04 - val_loss: 4.8983 - val_mse: 3.5283e-04\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.1981 - mse: 3.0812e-04 - val_loss: 4.9004 - val_mse: 3.5289e-04\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.1914 - mse: 3.0718e-04 - val_loss: 4.9025 - val_mse: 3.5297e-04\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.1849 - mse: 3.0623e-04 - val_loss: 4.9044 - val_mse: 3.5300e-04\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.1784 - mse: 3.0528e-04 - val_loss: 4.9065 - val_mse: 3.5307e-04\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.1720 - mse: 3.0433e-04 - val_loss: 4.9087 - val_mse: 3.5314e-04\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.1657 - mse: 3.0341e-04 - val_loss: 4.9109 - val_mse: 3.5321e-04\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.1595 - mse: 3.0249e-04 - val_loss: 4.9131 - val_mse: 3.5328e-04\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.1534 - mse: 3.0155e-04 - val_loss: 4.9152 - val_mse: 3.5335e-04\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.1474 - mse: 3.0065e-04 - val_loss: 4.9174 - val_mse: 3.5342e-04\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.1414 - mse: 2.9972e-04 - val_loss: 4.9196 - val_mse: 3.5349e-04\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.1355 - mse: 2.9881e-04 - val_loss: 4.9220 - val_mse: 3.5357e-04\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.1296 - mse: 2.9790e-04 - val_loss: 4.9241 - val_mse: 3.5363e-04\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.1239 - mse: 2.9702e-04 - val_loss: 4.9263 - val_mse: 3.5372e-04\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.1182 - mse: 2.9613e-04 - val_loss: 4.9287 - val_mse: 3.5379e-04\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.1125 - mse: 2.9524e-04 - val_loss: 4.9310 - val_mse: 3.5387e-04\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.1070 - mse: 2.9437e-04 - val_loss: 4.9334 - val_mse: 3.5397e-04\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 4.1015 - mse: 2.9350e-04 - val_loss: 4.9357 - val_mse: 3.5407e-04\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.0961 - mse: 2.9261e-04 - val_loss: 4.9380 - val_mse: 3.5413e-04\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.0907 - mse: 2.9175e-04 - val_loss: 4.9404 - val_mse: 3.5422e-04\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.0855 - mse: 2.9091e-04 - val_loss: 4.9428 - val_mse: 3.5431e-04\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.0802 - mse: 2.9006e-04 - val_loss: 4.9451 - val_mse: 3.5440e-04\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.0751 - mse: 2.8921e-04 - val_loss: 4.9476 - val_mse: 3.5451e-04\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.0700 - mse: 2.8838e-04 - val_loss: 4.9498 - val_mse: 3.5459e-04\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.0649 - mse: 2.8756e-04 - val_loss: 4.9523 - val_mse: 3.5469e-04\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.0599 - mse: 2.8674e-04 - val_loss: 4.9548 - val_mse: 3.5479e-04\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.0550 - mse: 2.8592e-04 - val_loss: 4.9572 - val_mse: 3.5490e-04\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.0501 - mse: 2.8511e-04 - val_loss: 4.9597 - val_mse: 3.5500e-04\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.0453 - mse: 2.8431e-04 - val_loss: 4.9621 - val_mse: 3.5511e-04\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.0405 - mse: 2.8352e-04 - val_loss: 4.9645 - val_mse: 3.5520e-04\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.0358 - mse: 2.8274e-04 - val_loss: 4.9670 - val_mse: 3.5531e-04\n",
      "VAE 1491 100\n",
      "(3807, 1491) (423, 1491)\n",
      "(3807, 536) (423, 536)\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 6.2266 - mse: 3.7995e-04 - val_loss: 6.1550 - val_mse: 3.7792e-04\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 6.0480 - mse: 3.7851e-04 - val_loss: 6.0342 - val_mse: 3.7689e-04\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 5.8814 - mse: 3.7690e-04 - val_loss: 5.9203 - val_mse: 3.7580e-04\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 5.7233 - mse: 3.7507e-04 - val_loss: 5.8156 - val_mse: 3.7466e-04\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 5.5738 - mse: 3.7297e-04 - val_loss: 5.7184 - val_mse: 3.7346e-04\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 5.4328 - mse: 3.7058e-04 - val_loss: 5.6288 - val_mse: 3.7222e-04\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 5.3001 - mse: 3.6787e-04 - val_loss: 5.5469 - val_mse: 3.7095e-04\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 5.1754 - mse: 3.6476e-04 - val_loss: 5.4715 - val_mse: 3.6964e-04\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 5.0584 - mse: 3.6123e-04 - val_loss: 5.4035 - val_mse: 3.6832e-04\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 4.9489 - mse: 3.5725e-04 - val_loss: 5.3419 - val_mse: 3.6698e-04\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.8468 - mse: 3.5279e-04 - val_loss: 5.2857 - val_mse: 3.6564e-04\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 4.7515 - mse: 3.4788e-04 - val_loss: 5.2358 - val_mse: 3.6431e-04\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 4.6628 - mse: 3.4254e-04 - val_loss: 5.1912 - val_mse: 3.6302e-04\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 4.5802 - mse: 3.3689e-04 - val_loss: 5.1518 - val_mse: 3.6176e-04\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 4.5037 - mse: 3.3096e-04 - val_loss: 5.1168 - val_mse: 3.6055e-04\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.4327 - mse: 3.2483e-04 - val_loss: 5.0861 - val_mse: 3.5940e-04\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 3ms/step - loss: 4.3668 - mse: 3.1852e-04 - val_loss: 5.0588 - val_mse: 3.5829e-04\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 4.3057 - mse: 3.1221e-04 - val_loss: 5.0359 - val_mse: 3.5731e-04\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 4.2490 - mse: 3.0587e-04 - val_loss: 5.0161 - val_mse: 3.5639e-04\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 4.1964 - mse: 2.9951e-04 - val_loss: 4.9992 - val_mse: 3.5558e-04\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 4.1477 - mse: 2.9327e-04 - val_loss: 4.9850 - val_mse: 3.5487e-04\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 4.1022 - mse: 2.8710e-04 - val_loss: 4.9733 - val_mse: 3.5427e-04\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 4.0599 - mse: 2.8106e-04 - val_loss: 4.9634 - val_mse: 3.5377e-04\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 4.0203 - mse: 2.7516e-04 - val_loss: 4.9560 - val_mse: 3.5336e-04\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 3.9834 - mse: 2.6933e-04 - val_loss: 4.9499 - val_mse: 3.5306e-04\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 3.9487 - mse: 2.6373e-04 - val_loss: 4.9452 - val_mse: 3.5284e-04\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.9163 - mse: 2.5832e-04 - val_loss: 4.9423 - val_mse: 3.5271e-04\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.8857 - mse: 2.5306e-04 - val_loss: 4.9405 - val_mse: 3.5271e-04\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 3.8569 - mse: 2.4799e-04 - val_loss: 4.9395 - val_mse: 3.5270e-04\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 3.8295 - mse: 2.4311e-04 - val_loss: 4.9395 - val_mse: 3.5283e-04\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 3.8037 - mse: 2.3841e-04 - val_loss: 4.9405 - val_mse: 3.5303e-04\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 3.7791 - mse: 2.3389e-04 - val_loss: 4.9422 - val_mse: 3.5326e-04\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.7558 - mse: 2.2954e-04 - val_loss: 4.9444 - val_mse: 3.5357e-04\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.7334 - mse: 2.2530e-04 - val_loss: 4.9469 - val_mse: 3.5385e-04\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 3.7121 - mse: 2.2126e-04 - val_loss: 4.9501 - val_mse: 3.5422e-04\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.6916 - mse: 2.1738e-04 - val_loss: 4.9539 - val_mse: 3.5459e-04\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.6721 - mse: 2.1360e-04 - val_loss: 4.9578 - val_mse: 3.5505e-04\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.6532 - mse: 2.0998e-04 - val_loss: 4.9624 - val_mse: 3.5548e-04\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.6351 - mse: 2.0652e-04 - val_loss: 4.9670 - val_mse: 3.5598e-04\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.6176 - mse: 2.0311e-04 - val_loss: 4.9718 - val_mse: 3.5647e-04\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.6008 - mse: 1.9991e-04 - val_loss: 4.9768 - val_mse: 3.5700e-04\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 3.5844 - mse: 1.9671e-04 - val_loss: 4.9821 - val_mse: 3.5754e-04\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.5688 - mse: 1.9370e-04 - val_loss: 4.9876 - val_mse: 3.5811e-04\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 3.5535 - mse: 1.9075e-04 - val_loss: 4.9935 - val_mse: 3.5864e-04\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.5388 - mse: 1.8791e-04 - val_loss: 4.9992 - val_mse: 3.5930e-04\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.5245 - mse: 1.8518e-04 - val_loss: 5.0049 - val_mse: 3.5987e-04\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 3.5106 - mse: 1.8255e-04 - val_loss: 5.0111 - val_mse: 3.6051e-04\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.4971 - mse: 1.7998e-04 - val_loss: 5.0175 - val_mse: 3.6118e-04\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 3.4840 - mse: 1.7743e-04 - val_loss: 5.0237 - val_mse: 3.6185e-04\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.4714 - mse: 1.7506e-04 - val_loss: 5.0300 - val_mse: 3.6251e-04\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.4589 - mse: 1.7270e-04 - val_loss: 5.0365 - val_mse: 3.6316e-04\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.4470 - mse: 1.7048e-04 - val_loss: 5.0431 - val_mse: 3.6393e-04\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 3.4352 - mse: 1.6826e-04 - val_loss: 5.0495 - val_mse: 3.6461e-04\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 3.4238 - mse: 1.6613e-04 - val_loss: 5.0564 - val_mse: 3.6537e-04\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 3.4127 - mse: 1.6409e-04 - val_loss: 5.0629 - val_mse: 3.6607e-04\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 3.4019 - mse: 1.6207e-04 - val_loss: 5.0698 - val_mse: 3.6685e-04\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.3913 - mse: 1.6012e-04 - val_loss: 5.0768 - val_mse: 3.6765e-04\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.3810 - mse: 1.5823e-04 - val_loss: 5.0836 - val_mse: 3.6842e-04\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 3.3709 - mse: 1.5640e-04 - val_loss: 5.0902 - val_mse: 3.6914e-04\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.3611 - mse: 1.5458e-04 - val_loss: 5.0973 - val_mse: 3.6996e-04\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.3516 - mse: 1.5291e-04 - val_loss: 5.1043 - val_mse: 3.7079e-04\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.3421 - mse: 1.5117e-04 - val_loss: 5.1114 - val_mse: 3.7162e-04\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.3330 - mse: 1.4953e-04 - val_loss: 5.1187 - val_mse: 3.7241e-04\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.3241 - mse: 1.4789e-04 - val_loss: 5.1257 - val_mse: 3.7332e-04\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.3153 - mse: 1.4642e-04 - val_loss: 5.1331 - val_mse: 3.7418e-04\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 3.3067 - mse: 1.4483e-04 - val_loss: 5.1398 - val_mse: 3.7497e-04\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.2984 - mse: 1.4337e-04 - val_loss: 5.1472 - val_mse: 3.7585e-04\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.2902 - mse: 1.4187e-04 - val_loss: 5.1545 - val_mse: 3.7686e-04\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 3.2821 - mse: 1.4052e-04 - val_loss: 5.1620 - val_mse: 3.7769e-04\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.2744 - mse: 1.3913e-04 - val_loss: 5.1690 - val_mse: 3.7851e-04\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 3.2666 - mse: 1.3780e-04 - val_loss: 5.1763 - val_mse: 3.7945e-04\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 3.2591 - mse: 1.3640e-04 - val_loss: 5.1834 - val_mse: 3.8033e-04\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.2517 - mse: 1.3523e-04 - val_loss: 5.1909 - val_mse: 3.8123e-04\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.2445 - mse: 1.3392e-04 - val_loss: 5.1984 - val_mse: 3.8216e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.2374 - mse: 1.3266e-04 - val_loss: 5.2055 - val_mse: 3.8314e-04\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.2304 - mse: 1.3153e-04 - val_loss: 5.2131 - val_mse: 3.8402e-04\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.2236 - mse: 1.3035e-04 - val_loss: 5.2205 - val_mse: 3.8494e-04\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 3.2169 - mse: 1.2920e-04 - val_loss: 5.2281 - val_mse: 3.8589e-04\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 3.2103 - mse: 1.2811e-04 - val_loss: 5.2356 - val_mse: 3.8684e-04\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.2039 - mse: 1.2698e-04 - val_loss: 5.2427 - val_mse: 3.8775e-04\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 3.1977 - mse: 1.2597e-04 - val_loss: 5.2502 - val_mse: 3.8868e-04\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.1914 - mse: 1.2485e-04 - val_loss: 5.2578 - val_mse: 3.8967e-04\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 3.1854 - mse: 1.2388e-04 - val_loss: 5.2649 - val_mse: 3.9062e-04\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.1794 - mse: 1.2281e-04 - val_loss: 5.2722 - val_mse: 3.9147e-04\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.1735 - mse: 1.2191e-04 - val_loss: 5.2798 - val_mse: 3.9254e-04\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.1678 - mse: 1.2094e-04 - val_loss: 5.2875 - val_mse: 3.9351e-04\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.1621 - mse: 1.2001e-04 - val_loss: 5.2948 - val_mse: 3.9445e-04\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.1566 - mse: 1.1905e-04 - val_loss: 5.3023 - val_mse: 3.9542e-04\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.1511 - mse: 1.1819e-04 - val_loss: 5.3098 - val_mse: 3.9629e-04\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 3.1458 - mse: 1.1723e-04 - val_loss: 5.3175 - val_mse: 3.9743e-04\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.1405 - mse: 1.1646e-04 - val_loss: 5.3246 - val_mse: 3.9835e-04\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.1353 - mse: 1.1556e-04 - val_loss: 5.3321 - val_mse: 3.9931e-04\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 3.1302 - mse: 1.1471e-04 - val_loss: 5.3398 - val_mse: 4.0031e-04\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.1252 - mse: 1.1387e-04 - val_loss: 5.3470 - val_mse: 4.0118e-04\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 3.1202 - mse: 1.1316e-04 - val_loss: 5.3544 - val_mse: 4.0220e-04\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 3.1153 - mse: 1.1230e-04 - val_loss: 5.3617 - val_mse: 4.0316e-04\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.1106 - mse: 1.1164e-04 - val_loss: 5.3693 - val_mse: 4.0411e-04\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 3.1059 - mse: 1.1077e-04 - val_loss: 5.3768 - val_mse: 4.0519e-04\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.1013 - mse: 1.1009e-04 - val_loss: 5.3841 - val_mse: 4.0614e-04\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 3.0968 - mse: 1.0932e-04 - val_loss: 5.3914 - val_mse: 4.0704e-04\n"
     ]
    }
   ],
   "source": [
    "# Make results dir\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "save_dir = os.path.join('./results', dt_string)\n",
    "os.makedirs(save_dir)\n",
    "\n",
    "print(\"Save dir is \", save_dir)\n",
    "\n",
    "\n",
    "for i in range(len(pca_components)):\n",
    "    print(\"VAE {} {}\".format(pca_components[i], variances[i]))\n",
    "\n",
    "    train_split, val_split = splits[0]\n",
    "    \n",
    "    X_vae = np.load(\"./vae/VanillaVAE/latent_features_trainval_beta1.0_latentdim{}.npy\".format(pca_components[i]))\n",
    "\n",
    "    x_train = X_vae[:len(train_split)]\n",
    "    x_valid = X_vae[len(train_split):]\n",
    "    \n",
    "    y_train = y_deletion[train_split]\n",
    "    y_valid = y_deletion[val_split]\n",
    "    \n",
    "    print(x_train.shape, x_valid.shape)\n",
    "\n",
    "    print(y_train.shape, y_valid.shape)\n",
    "\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"{}/logs/vae_beta1_latentdim{}\".format(save_dir, pca_components[i]))\n",
    "    \n",
    "    checkpoint_name = save_dir + '/vae_beta1_latentdim{}_cp{}'.format(pca_components[i], i)\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath= checkpoint_name + '-{epoch:02d}.h5',\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode=\"min\")\n",
    "    \n",
    "    csv_logger = CSVLogger('{}/vae_beta1_latendim{}.log'.format(save_dir, pca_components[i]), separator=',', append=False)\n",
    "\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(536,  activation='softmax', input_shape=(x_train.shape[1],), kernel_regularizer=None))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['mse'])\n",
    "    history = model.fit(x_train, y_train, epochs=100, validation_data=(x_valid, y_valid),\n",
    "              callbacks=[\n",
    "                  tensorboard_callback,\n",
    "                  model_checkpoint_callback,\n",
    "                  csv_logger], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "200e6591",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = pd.read_csv(\"/home/bram/lindel423/data/Lindel_ForeCasT_testset_4000+samples.txt\", sep='\\t').values[:,1:].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcc72496",
   "metadata": {},
   "outputs": [],
   "source": [
    "fX = forecast[:, :(2649 + 384)]\n",
    "fy = forecast[:, (2649 + 384):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c853a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4737, 557)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2647a332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Models\n",
    "trained_model = load_model('/home/bram/lindel423/results/VAE/vae_beta1_latentdim180_cp1-74.h5')\n",
    "history = pd.read_csv('/home/bram/lindel423/results/VAE/vae_beta1_latendim180.log')\n",
    "vae_y = np.load('./vae/VanillaVAE/latent_features_test_beta1.0_latentdim180.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "001cf084",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00034762413"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = trained_model.predict(vae_y)\n",
    "mse(y_hat, y_test_deletion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad4114e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "epoch       80.000000\n",
       "loss         4.824185\n",
       "mse          0.000355\n",
       "val_loss     4.874755\n",
       "val_mse      0.000354\n",
       "Name: 80, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.iloc[80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4043b904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473bd2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fbe16a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2 : MCA\n",
    "\"\"\"\n",
    "Multiple correspondence analysis (MCA) is an extension of correspondence analysis (CA).\n",
    "It should be used when you have more than two categorical variables.\n",
    "The idea is simply to compute the one-hot encoded version of a dataset and apply CA on it.\n",
    "As an example we're going to use the balloons dataset taken from the UCI datasets website.\n",
    "\"\"\"\n",
    "mca_obj = MCA(data.iloc[:, 1:])\n",
    "\n",
    "row_factor_scores = mca_obj.fs_r(percent=0.99)\n",
    "print(\"Row factor scores (99% variance explained) shape : \", row_factor_scores.shape)\n",
    "\n",
    "column_factor_scores = mca_obj.fs_c(percent=0.99)\n",
    "print(\"Column factor scores (99% variance explained) shape : \", column_factor_scores.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc512c42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3 : FA\n",
    "\n",
    "# Instantiate factor analysis object\n",
    "from factor_analyzer.factor_analyzer import FactorAnalyzer \n",
    "fa = FactorAnalyzer(rotation='varimax')\n",
    "fa.fit(data.iloc[:, 1:])\n",
    "# Check Eigenvalues\n",
    "ev, v = fa.get_eigenvalues()\n",
    "ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad32498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b34dc2307e58e1a1d1e57cf7ef01b077b034c069b8a201720687e01a8602b64b"
  },
  "kernelspec": {
   "display_name": "bio",
   "language": "python",
   "name": "bio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}